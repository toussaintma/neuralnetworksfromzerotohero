{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwGKxz34p26O/J8YSwCx3j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toussaintma/neuralnetworksfromzerotohero/blob/main/walkthrough_makemore_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hwpya_9rcRB_"
      },
      "outputs": [],
      "source": [
        "# data and code at https://github.com/karpathy/makemore\n",
        "# course at https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2&t=11s"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Next character probability"
      ],
      "metadata": {
        "id": "JoftShkPl7wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "gY0brpEBdN1B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_words = pd.read_csv('names.txt', header=None, names=['name'])"
      ],
      "metadata": {
        "id": "Rt1J4UzmdiGk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_words.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27rhtQACdwq1",
        "outputId": "70e8db84-6181-4590-b035-1a072d5a0f61"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32033, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_words['name']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw-Ia2pWfJpa",
        "outputId": "23f1843d-13b4-4b75-c5d9-f1e02d44b5bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            emma\n",
              "1          olivia\n",
              "2             ava\n",
              "3        isabella\n",
              "4          sophia\n",
              "           ...   \n",
              "32028       zylas\n",
              "32029       zyran\n",
              "32030       zyrie\n",
              "32031       zyron\n",
              "32032       zzyzx\n",
              "Name: name, Length: 32033, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stat = {}\n",
        "for w in df_words.loc[:, 'name']:\n",
        "  w = '.' + w + '.'\n",
        "  for ch1, ch2 in zip(w, w[1:]):\n",
        "    #print(ch1, ch2, sep='')\n",
        "    if ch1 + ch2 in stat:\n",
        "      stat[ch1 + ch2] += 1\n",
        "    else:\n",
        "      stat[ch1 + ch2] = 1\n",
        "len(stat)"
      ],
      "metadata": {
        "id": "zOeCFOI9eZf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11f27d0-6c7e-4ab7-9a82-cb2e227d71c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "627"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stat['em']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ou-YMItc3Uk",
        "outputId": "e9687583-f14c-4b62-8b39-75e35fd810cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "769"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(stat.items(), key = lambda v: -v[1])[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQbbkkc62pI7",
        "outputId": "be4edb7c-a9cb-4087-b1bb-704fc8d78cfb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('n.', 6763),\n",
              " ('a.', 6640),\n",
              " ('an', 5438),\n",
              " ('.a', 4410),\n",
              " ('e.', 3983),\n",
              " ('ar', 3264),\n",
              " ('el', 3248),\n",
              " ('ri', 3033),\n",
              " ('na', 2977),\n",
              " ('.k', 2963)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_index(c):\n",
        "  result = 0\n",
        "  if (c != '.'):\n",
        "    result = ord(c) - ord('a') + 1\n",
        "  return result\n",
        "\n",
        "def get_char(i):\n",
        "  result = '.'\n",
        "  if (i != 0):\n",
        "    result = chr(ord('a') + i - 1)\n",
        "  return result\n",
        "get_index('e'), get_index('m'), get_index(get_char(4)), get_index('.'), get_char(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59to8CXmh214",
        "outputId": "4125700d-1d3c-4679-f9f4-3d9fa4ca1814"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 13, 4, 0, '.')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stat['.a'], stat['a.']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-resh-_TuKwC",
        "outputId": "add3125f-6d98-4a63-ad32-40a3e1710fea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4410, 6640)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats = [[0 for i in range(27)] for j in range(27)]\n",
        "len(stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7O3AYV5j9WA",
        "outputId": "b10ee06c-eaf8-49d5-9b93-e4510456b710"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in stat.items():\n",
        "  stats[get_index(k[0])][get_index(k[1])] = v\n",
        "t_stats = torch.tensor(stats, dtype=torch.float32)\n",
        "t_stats.shape, t_stats.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuPdQ1kJkMzG",
        "outputId": "7ff641ca-7e35-4c7a-cc47-f3a52c0357cc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([27, 27]), 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_stats[5, 13] # is 'em' = 769"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ2VyvduezO9",
        "outputId": "39abf4c7-d482-4bd9-de1f-1cbbf516d217"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(769.)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_stats.sum(dim=1, keepdim=True).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60n3O6DfkDKS",
        "outputId": "f85a0205-2354-4719-ac7a-566d73aec594"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_stats = t_stats / t_stats.sum(dim=-1).unsqueeze(-1) # a is 556/27245 found 2.0407e-02 OK\n",
        "t_stats[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wTUijABfZG4",
        "outputId": "f888cf37-ace0-4b90-8a4a-cc865e1541ca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
              "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
              "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_stats.sum(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVg6oXi1hCfd",
        "outputId": "9f57a9fd-5b1b-4dab-d5c5-94a1b5d71408"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = torch.multinomial(t_stats, 20, replacement=True)\n",
        "result = '.'\n",
        "next_char = '.'\n",
        "done = False\n",
        "for i in range(10):\n",
        "  next_char = get_char(sample[get_index(next_char)][i])\n",
        "  if (next_char == '.'):\n",
        "    done = True\n",
        "  if (not done):\n",
        "    result = result + next_char\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngTt1E8JlrFD",
        "outputId": "eed088d3-8384-4f8a-bd4b-abf478e105c8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".rran\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_stats[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUDS89sM0KnA",
        "outputId": "f0100465-7b01-4c36-cf4e-c4ab6d7bdee2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
              "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
              "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXxbTCyKBqkg",
        "outputId": "fd2f6f9f-9ccd-4f96-f21d-c96b53efa2a7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ll = 0\n",
        "n = 0\n",
        "result = []\n",
        "for w in df_words.loc[:, 'name']:\n",
        "  w = '.' + w + '.'\n",
        "  for ch1, ch2 in zip(w, w[1:]):\n",
        "    newll = torch.log(t_stats[get_index(ch1)][get_index(ch2)])\n",
        "    n += 1\n",
        "    ll += newll.item()\n",
        "    result.append([ch1, ch2, newll, ll])\n",
        "ll # should be -38.7856 for the first 3 words\n",
        "ll /= n\n",
        "nll = - ll\n",
        "nll"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQG7ip4s_LVB",
        "outputId": "d0044a04-ea68-402b-ec83-9e4c89e6e1b0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.4540144946949742"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: neuron net"
      ],
      "metadata": {
        "id": "QNbb1FDOlxmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs = []\n",
        "ys = []\n",
        "\n",
        "for w in df_words.loc[:, 'name']:\n",
        "  chs = '.' + w + '.'\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = get_index(ch1)\n",
        "    ix2 = get_index(ch2)\n",
        "    #print(ch1, ch2)\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "#xs, ys\n",
        "num = xs.nelement()\n",
        "print(num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA3x0if9mDsC",
        "outputId": "b1aa3f5c-75c3-4582-bd17-30cb3c7ca4e3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "228146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "xenc = F.one_hot(xs, 27).float()\n",
        "yenc = F.one_hot(ys, 27).float()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#plt.imshow(xenc)"
      ],
      "metadata": {
        "id": "dc0Ke6UurIGC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.randn((27, 27), requires_grad=True)\n",
        "r = xenc @ W\n",
        "xenc.shape, W.shape, r.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r5rU6-AsKUb",
        "outputId": "58720ada-c3ad-4ee1-bd0e-735905a0d14d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([228146, 27]), torch.Size([27, 27]), torch.Size([228146, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a in range(100):\n",
        "  logits = xenc @ W # log counts\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(dim=1, keepdim=True)\n",
        "  probs[0].sum(), probs\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01 * (W**2).mean()\n",
        "  print(loss.item())\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "  W.data += -50 * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvWerc4av4Qt",
        "outputId": "a6eaa3a5-0a8d-4a3c-e369-2882d5cd2613"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.8227946758270264\n",
            "3.4095218181610107\n",
            "3.1734468936920166\n",
            "3.032843589782715\n",
            "2.9366872310638428\n",
            "2.8647685050964355\n",
            "2.8096301555633545\n",
            "2.767125129699707\n",
            "2.7341184616088867\n",
            "2.7079622745513916\n",
            "2.686631679534912\n",
            "2.668767213821411\n",
            "2.653508424758911\n",
            "2.640298843383789\n",
            "2.628753662109375\n",
            "2.618584394454956\n",
            "2.6095659732818604\n",
            "2.601515293121338\n",
            "2.594285249710083\n",
            "2.587754726409912\n",
            "2.5818264484405518\n",
            "2.576420307159424\n",
            "2.571469306945801\n",
            "2.566920042037964\n",
            "2.5627267360687256\n",
            "2.558849573135376\n",
            "2.5552568435668945\n",
            "2.551919460296631\n",
            "2.5488131046295166\n",
            "2.5459158420562744\n",
            "2.5432090759277344\n",
            "2.540675401687622\n",
            "2.5383007526397705\n",
            "2.536071538925171\n",
            "2.533975601196289\n",
            "2.5320029258728027\n",
            "2.5301427841186523\n",
            "2.5283870697021484\n",
            "2.5267281532287598\n",
            "2.525158166885376\n",
            "2.5236706733703613\n",
            "2.5222601890563965\n",
            "2.520920515060425\n",
            "2.5196473598480225\n",
            "2.5184357166290283\n",
            "2.5172817707061768\n",
            "2.516181230545044\n",
            "2.5151307582855225\n",
            "2.514127492904663\n",
            "2.5131680965423584\n",
            "2.5122499465942383\n",
            "2.5113704204559326\n",
            "2.5105276107788086\n",
            "2.509718894958496\n",
            "2.508942127227783\n",
            "2.5081963539123535\n",
            "2.507479667663574\n",
            "2.5067896842956543\n",
            "2.5061256885528564\n",
            "2.505486249923706\n",
            "2.5048699378967285\n",
            "2.5042757987976074\n",
            "2.503702402114868\n",
            "2.5031490325927734\n",
            "2.5026144981384277\n",
            "2.502098560333252\n",
            "2.5015993118286133\n",
            "2.5011165142059326\n",
            "2.5006494522094727\n",
            "2.500197410583496\n",
            "2.4997596740722656\n",
            "2.499336004257202\n",
            "2.49892520904541\n",
            "2.4985272884368896\n",
            "2.498141288757324\n",
            "2.4977664947509766\n",
            "2.497403621673584\n",
            "2.4970507621765137\n",
            "2.496708393096924\n",
            "2.496375799179077\n",
            "2.4960527420043945\n",
            "2.4957387447357178\n",
            "2.4954335689544678\n",
            "2.4951364994049072\n",
            "2.4948480129241943\n",
            "2.494567394256592\n",
            "2.4942941665649414\n",
            "2.494028329849243\n",
            "2.4937691688537598\n",
            "2.4935176372528076\n",
            "2.493271827697754\n",
            "2.493032693862915\n",
            "2.4927995204925537\n",
            "2.492572784423828\n",
            "2.4923512935638428\n",
            "2.492135524749756\n",
            "2.49192476272583\n",
            "2.4917197227478027\n",
            "2.491518974304199\n",
            "2.491323947906494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nlls = torch.zeros(5)\n",
        "#for i in range(5):\n",
        "#  x = xs[i].item()\n",
        "#  y = ys[i].item()\n",
        "#  print(f'bigram example {i+1}: {get_char(x)}{get_char(y)} index {x}, {y}')\n",
        "#  print(f'input to the neural net: {x}')\n",
        "#  print(f'output probabilities: {probs[i]}')\n",
        "#  print(f'label: {y}')\n",
        "#  p = probs[i, y]\n",
        "#  print(f'probability assigned to the correct character: {p.item()}')\n",
        "#  logp = torch.log(p)\n",
        "#  print(f'log likelyhood: {logp.item()}')\n",
        "#  nll = - logp\n",
        "#  print(f'negative log likelyhood: {nll}')\n",
        "# nlls[i] = nll\n",
        "# print(f'average nll: {nlls.mean().item()}')\n"
      ],
      "metadata": {
        "id": "_km7bq9Kyhj_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bigram_nn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(27, 27, bias=False),\n",
        "            nn.LogSoftmax(dim=1))\n",
        "    def forward(self, x):\n",
        "        logits = self.linear(x)\n",
        "        return logits\n",
        "\n",
        "model = Bigram_nn()\n",
        "loss_fn = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=50)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZJcUkvT2Y-z",
        "outputId": "a1c3939b-d94d-44b1-fb9c-73b33c484006"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bigram_nn(\n",
              "  (linear): Sequential(\n",
              "    (0): Linear(in_features=27, out_features=27, bias=False)\n",
              "    (1): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(100):\n",
        "  preds = model(xenc)\n",
        "  loss = loss_fn(preds, ys)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "print(f\"step {e+1} {loss:.3f}\") #, end=\"; \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZM5sVG66c3e",
        "outputId": "c30200f7-1290-459f-ce48-201c429a9026"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 100 2.471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercises"
      ],
      "metadata": {
        "id": "oqUQ6_XVNivn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trigram model\n",
        "x_l = []\n",
        "y_l = []\n",
        "tri_index = []\n",
        "\n",
        "def stoi(bi):\n",
        "  if not(bi in tri_index):\n",
        "    tri_index.append(bi)\n",
        "  return tri_index.index(bi)\n",
        "\n",
        "\n",
        "for w in df_words.loc[:, 'name']:\n",
        "  chs = '.' + w + '.'\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi(ch1 + ch2)\n",
        "    ix3 = get_index(ch3)\n",
        "    #print(ch1, ch2, ch3)\n",
        "    x_l.append(ix1)\n",
        "    y_l.append(ix3)\n",
        "\n",
        "x_l = torch.tensor(x_l)\n",
        "y_l = torch.tensor(y_l)\n",
        "num = len(tri_index)\n",
        "print(num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbMKeXis7qi4",
        "outputId": "5c189893-22f7-4385-b299-07ed4d82c983"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_lenc = F.one_hot(x_l, num).float()\n",
        "x_lenc.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gI5prfJPk57",
        "outputId": "4be12d40-1b3a-4e11-8329-ce478dd3c163"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([196113, 601])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Trigram_nn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(num, 27, bias=False),\n",
        "            nn.LogSoftmax(dim=1))\n",
        "    def forward(self, x):\n",
        "        logits = self.linear(x)\n",
        "        return logits\n",
        "\n",
        "model = Trigram_nn()\n",
        "loss_fn = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=50)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtTEjdi4P_CN",
        "outputId": "a3045cb5-cad7-479f-ff16-0397f97c89f4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Trigram_nn(\n",
              "  (linear): Sequential(\n",
              "    (0): Linear(in_features=601, out_features=27, bias=False)\n",
              "    (1): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(200):\n",
        "  preds = model(x_lenc)\n",
        "  loss = loss_fn(preds, y_l)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "print(f\"step {e+1} {loss:.3f}\") #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bttS3W8EQMOf",
        "outputId": "c9a54bd1-8a58-4e67-d86f-07c9a7f083ea"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 200 2.211\n"
          ]
        }
      ]
    }
  ]
}